---
layout: post
title: "Day 30 –Model Accuracy, Data Finding"
date: 2025-07-07
author: Arpana Basnet
permalink: /day30.html
tags: []

what_i_learned: |
  Today, I focused primarily on addressing a major limitation in our machine learning project the lack of sufficient data. After reviewing the performance of our model, we found that the accuracy was stuck at around 79%, even after trying a range of different approaches. We experimented with various classification algorithms, tuned hyperparameters, and tested different preprocessing techniques, but none of these strategies gave us the improvement we were hoping for.
  
  After a team discussion, we came to the conclusion that the issue wasn’t with the model itself it was with the data. Our dataset wasn’t large or diverse enough to help the model generalize well. So, I spent most of the day searching for additional RNA seq datasets that could support and enrich our current sample set. This involved navigating public repositories like GEO and filtering for datasets that include proper labeling and tumor grading information, such as benign vs malignant and WHO grades.
  
  While I was working on that, Skyler did a brief but helpful code review of everything we’ve implemented so far. This allowed us to check that our preprocessing steps, feature selection methods, and model evaluation techniques were correctly set up and functioning as expected. His review helped us identify a few areas where we could clean up or clarify our logic for better results in the next phase of testing.
blockers: |
  Today, One of the main blockers we faced today was the limited size and quality of our existing dataset. Despite applying multiple machine learning models and optimization techniques, the accuracy plateaued at 79%, which clearly indicated that the model couldn’t improve further without more informative data. Another challenge was that some of the public datasets lacked clear tumor grading or consistent labeling, making it time-consuming to find and filter the right samples. Additionally, we had minor technical issues related to file encoding and formatting when trying to preprocess newly downloaded datasets, which slowed down our progress temporarily. These issues reminded us how important data consistency and proper documentation are in biomedical machine learning projects.
  
reflection: |
   Today, work made me realize how essential high-quality and well labeled data is in building effective machine learning models especially in biomedical research. Even though we reached a 79% accuracy with our current dataset, the lack of further improvement showed us the limitations of working with insufficient or inconsistent data. It was frustrating at first because we had already tried so many modeling techniques, but it was also a valuable learning moment. Instead of continuing to tweak the model endlessly, we stepped back and identified the real issue: the dataset itself. This shift in focus helped us be more strategic and data driven in our decision making. Collaborating with Skyler also reminded me of the importance of code reviews and teamwork in long-term projects. Overall, today strengthened my understanding that in machine learning, the quality of your data often matters more than the complexity of your model.
---







