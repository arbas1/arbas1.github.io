---
layout: post
title: "Day 33 –Improving Model Performance and Writing Skills"
date: 2025-07-10
author: Arpana Basnet
permalink: /day33.html
tags: []

what_i_learned: |
  Today, we had a session with Ms. Pandey and her team from the Writing Department. The focus of the session was on strengthening our academic writing skills. Ms. Pandey taught us what makes effective writing, how to structure our reports, and how to avoid common mistakes. She explained the importance of clarity, flow, and grammar when preparing research summaries or reflections.
  
  Alongside the writing session, we continued working on our brain tumor classification project using gene expression data. We applied differential expression analysis (DEG) using t-tests to filter statistically significant genes, followed by log2 fold change to identify meaningful biological differences. We used SMOTE to balance the dataset and tried multiple models including Logistic Regression, Random Forest, XGBoost, KNN, AdaBoost, and SVM. We also tested feature selection using L1-SVM, but the accuracy stayed below our goal of 80%. We explored PCA, but it didn’t improve performance either. We are now working on analyzing top reactive genes and visualizing the results using bar plots and volcano plots for better understanding and evidence.
blockers: |
  Today, we faced difficulty improving model accuracy above 80%, despite trying various algorithms like Random Forest, XGBoost, and SVM. Using PCA for dimensionality reduction did not help and made the results harder to interpret biologically. L1-SVM feature selection also didn’t lead to better performance than our DEG based approach. Although we generated volcano plots, we struggled to connect them directly to stronger classification outcomes. The writing session with Ms. Pandey was helpful for general writing tips.
  
reflection: |
   Today was a mix of learning and troubleshooting. The session with Ms. Pandey helped reinforce the importance of clear writing, especially as we prepare to explain our complex machine learning project to others. On the technical side, we applied several models and methods like SMOTE, DEG filtering, PCA, and L1-SVM, but still couldn’t reach the desired accuracy above 80%. This reminded us that model performance can be unpredictable and often requires deeper tuning and experimentation.
---










