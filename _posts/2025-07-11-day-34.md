---
layout: post
title: "Day 34 –Improving Model Reliability Through Better Data Practices"
date: 2025-07-11
author: Arpana Basnet
permalink: /day34.html
tags: []

what_i_learned: |
  Today, was one of the most productive and insightful days of my project so far. I started by revisiting my machine learning pipeline to make sure I was handling the data correctly. One of the major improvements I made was applying SMOTE only to the training set, instead of the whole dataset like I did earlier. This helped prevent data leakage and made the model evaluation more realistic. After applying SMOTE, I scaled the data so the model wouldn’t be biased by large expression values.
  
  I also spent time identifying the most reactive genes using two different methods mutual information and log2 fold change  which gave me a clearer picture of which genes actually matter when distinguishing between malignant and benign samples. That helped me select stronger, more meaningful features for model training.
  
  Once the data was ready, I trained multiple machine learning models including Logistic Regression, Random Forest, XGBoost, SVM, KNN, and AdaBoost. Then I tested them on the untouched test set and evaluated their performance using accuracy, F1 score, and ROC AUC. It was really interesting to see how models like XGBoost consistently outperformed others, and how performance metrics shifted depending on how the data was handled.
blockers: |
  One of the main blockers I faced today was realizing that I had initially applied SMOTE to the entire dataset instead of just the training data, which led to data leakage and gave misleading model results. Figuring out the correct order—applying SMOTE after splitting, then scaling—took some trial and error. I also ran into challenges with certain models like SVM, which didn’t perform as well as expected, and I had to spend extra time comparing their behavior. Another blocker was understanding why some of the top genes identified by mutual information didn’t overlap with those from the log2 fold change method, which made it harder to decide which features to use.
  
reflection: |
   Today’s work helped me realize how important it is to follow the right order when preparing data for machine learning. Fixing the SMOTE placement and avoiding data leakage made a big difference in the reliability of my model results. I also learned that different feature selection methods, like mutual information and log2 fold change, can highlight very different genes, and that it's okay to combine both to get a broader picture. Testing multiple models gave me better insight into how each one handles the data, and it reminded me that performance isn’t just about accuracy it’s about how well a model generalizes. Overall, today gave me more confidence in both my technical process and in interpreting the results I'm seeing.
---











